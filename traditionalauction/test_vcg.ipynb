{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import truncnorm\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "\n",
    "\n",
    "from networkx.algorithms import bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle(data, language=\"marginal\", n_best_items=None):\n",
    "    \"\"\"\n",
    "    Allocation oracle.\n",
    "    :param data: tensor with bids (valuations) in auctions shaped as (batch_size, n_agents, n_items)\n",
    "    :param language: bidding language, either\n",
    "        'additive' for heterogenous goods and additive utilities,\n",
    "        'marginal' for homogenous goods and marginally decreasing utilities\n",
    "            (utility of a bundle is sum of item-wise utilities, s.t. each new item produces less utility) or\n",
    "        'unit-demand' for heterogenous goods and unit demand (utility of a bundle is max of item-wise utilities)\n",
    "        * 'hierarchical' for hierarchical bundles?\n",
    "    :param n_best_items: number of items to allocate, the default is all items\n",
    "    :return: allocation, i.e. binary tensor with same shape as valuation\n",
    "    \"\"\"\n",
    "\n",
    "    size, n_participants, n_items = data.size()\n",
    "    if n_best_items is None:\n",
    "        n_best_items = n_items\n",
    "    n_best_items = min(n_best_items, n_items)\n",
    "\n",
    "    if language == \"additive\":\n",
    "        allocation = torch.argmax(data, 1, True)\n",
    "        allocation = F.one_hot(allocation)[:, 0].permute((0, 2, 1))\n",
    "        allocation = topk_allocation(data, allocation, n_best_items)\n",
    "\n",
    "    elif language == \"marginal\":\n",
    "        allocation = torch.zeros((size, n_participants)).long()\n",
    "        for i, auction in enumerate(data):\n",
    "            auction_copy = auction.clone()\n",
    "            v, idx = auction_copy[:, 0], torch.zeros((n_participants,)).long()\n",
    "            for j in range(n_best_items):\n",
    "                part = torch.argmax(v).item()\n",
    "                idx[part] += 1\n",
    "                if j != n_items - 1:\n",
    "                    v[part] = (\n",
    "                        auction_copy[part, idx[part]]\n",
    "                        - auction_copy[part, idx[part] - 1]\n",
    "                    )\n",
    "            allocation[i] = idx\n",
    "        allocation = torch.zeros(size, n_participants, n_items + 1).scatter_(\n",
    "            2, allocation.unsqueeze(-1), 1\n",
    "        )[:, :, 1:]\n",
    "\n",
    "    elif language == \"unit-demand\":\n",
    "        n_best_items = min(n_best_items, n_participants)\n",
    "        allocation = torch.zeros(size, n_participants, n_items)\n",
    "        for i, auction in enumerate(data):\n",
    "            allocation_cur = torch.zeros(n_participants, n_items)\n",
    "            graph = csr_matrix(-auction.detach().numpy())\n",
    "            graph = bipartite.from_biadjacency_matrix(graph)\n",
    "            matching = bipartite.matching.minimum_weight_full_matching(graph)\n",
    "            for part in range(n_participants):\n",
    "                if part in matching.keys():\n",
    "                    item = matching[part] - n_participants\n",
    "                    allocation_cur[part, item] = 1\n",
    "            allocation[i] = allocation_cur\n",
    "        allocation = topk_allocation(data, allocation, n_best_items)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"Only 'additive', 'marginal', and 'unit-demand' languages are implemented\"\n",
    "        )\n",
    "\n",
    "    return allocation\n",
    "\n",
    "\n",
    "def topk_allocation(data, allocation, n_best_items):\n",
    "    threshold = torch.topk(\n",
    "        (data * allocation).reshape(data.shape[0], -1), n_best_items, -1\n",
    "    )[0][:, -1].view(-1, 1, 1)\n",
    "    allocation[data < threshold] = 0\n",
    "    return allocation\n",
    "\n",
    "\n",
    "def get_v(data, allocation):\n",
    "    \"\"\"\n",
    "    :param data: tensor with bids (valuations) in auctions shaped as (batch_size, n_agents, n_items)\n",
    "    :param allocation: efficient allocation, output of oracle, binary tensor shaped as (batch_size, n_agents, n_items)\n",
    "\n",
    "    :return: total value of objects gained by each agent in each auction with respect to the efficient allocations,\n",
    "        tensor shaped as (batch_size, n_agents)\n",
    "    \"\"\"\n",
    "    return torch.sum(data * allocation, 2)\n",
    "\n",
    "\n",
    "def delete_agent(x, i):\n",
    "    mask = torch.ones(x.size()[1]).int()\n",
    "    mask[i] = 0\n",
    "    return x[:, mask.bool()]\n",
    "\n",
    "\n",
    "def get_v_sum_but_i(v):\n",
    "    return torch.cat(\n",
    "        [torch.sum(delete_agent(v, i), dim=1).view(-1, 1) for i in range(v.size()[1])],\n",
    "        dim=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VCG(batch, language=\"marginal\"):\n",
    "    \"\"\"\n",
    "    VCG efficient and truthful mechanism.\n",
    "    :param batch: tensor with bids (valuations) in auctions shaped as (batch_size, n_agents, n_items)\n",
    "    :return: VCG prices t, tensor shaped as (batch_size, n_agents)\n",
    "    \"\"\"\n",
    "    allocation = oracle(batch, language)\n",
    "    v = get_v(batch, allocation)\n",
    "    v_sum_but_i = get_v_sum_but_i(v)\n",
    "\n",
    "    h = []\n",
    "    for i in range(batch.shape[1]):\n",
    "        batch_cur = delete_agent(batch, i)\n",
    "        allocation_cur = oracle(batch_cur, language)\n",
    "        v_cur = get_v(batch_cur, allocation_cur)\n",
    "        v_sum_cur = v_cur.sum(dim=-1).view(-1, 1)\n",
    "        h.append(v_sum_cur)\n",
    "    h = torch.cat(h, dim=1)\n",
    "\n",
    "    t = h - v_sum_but_i\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1039317/1297483777.py:73: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cur_noise = (noise_factors[idx] - Q_min) / (Q_max - Q_min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100000,)\n",
      "payoff 1.8606773387390276\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    n_auctions, n_agents, n_items = 100000, 7, 3\n",
    "    x, y, z = n_auctions, n_agents, n_items\n",
    "    \n",
    "    def calc_data_rate():\n",
    "        W  = 10**6 # bandwidth\n",
    "        d_i = random.uniform(100, 200) # distance from user to BS\n",
    "        p_i_trans = random.uniform(0.4, 0.8) # transmit power of user\n",
    "        h_i = random.gauss(0, 1) # small-fading channel gain of user\n",
    "        sigma = 10**-17 # noise variance \n",
    "        P_i = W * np.log2(1 + (p_i_trans * abs(h_i) * (d_i ** -2)) / (W * sigma))\n",
    "\n",
    "        return P_i\n",
    "\n",
    "    def gen_truncnorm(mean, std, a, b, lens): \n",
    "        a_trunc = (a - mean) / std\n",
    "        b_trunc = (b - mean) / std\n",
    "\n",
    "        trunc_samples = truncnorm.rvs(\n",
    "        a_trunc, b_trunc, loc=mean, scale=std, size=lens)\n",
    "\n",
    "        return trunc_samples\n",
    "\n",
    "    P_vm = 10 ** 12 # processing power of VM\n",
    "    N_D = 4 * 10 ** 8 # number of data points\n",
    "    C_tot_flops = 13.31 * 10 ** 9 # total number of LDM FLOPs\n",
    "    B_mem = 2304 * 10 ** 9 # memory bandwidth (RTX 4060)\n",
    "    Q_thresh = 3840 * 2160 # threshold for resolution factor \n",
    "\n",
    "    gamma = 0.5\n",
    "    phi_1 = 0.5\n",
    "    phi_2 = 0.5\n",
    "\n",
    "    T_req_val = 0.1\n",
    "    Q_req_val = 2.0\n",
    "\n",
    "    k = [0.5 for i in range(8)]\n",
    "\n",
    "    def calc_comp_latency(file_size):\n",
    "        ans = gamma * (phi_1 * (C_tot_flops / P_vm) + (1 + phi_2) * (file_size / B_mem))\n",
    "        return ans\n",
    "\n",
    "    tot_latencies = []\n",
    "    tot_qualities = []\n",
    "    val = []\n",
    "\n",
    "    case_1, case_2, case_3, case_4 = [], [], [], []\n",
    "\n",
    "    file_sizes      = np.loadtxt('../file_sizes.txt')\n",
    "    res_factors     = np.loadtxt('../factors/res_factor.txt')\n",
    "    noise_factors   = np.loadtxt(\"../factors/noise_factor.txt\")\n",
    "    quality_factors = np.loadtxt(\"../factors/quality_factor.txt\")\n",
    "\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            for res in range(z):\n",
    "                idx = random.randint(0, len(file_sizes) - 1)\n",
    "                file_size = file_sizes[idx]\n",
    "\n",
    "                data_rate = calc_data_rate()\n",
    "\n",
    "                trans_latency = file_size / data_rate\n",
    "                comp_latency = calc_comp_latency(file_size)\n",
    "                ret_latency = file_size / data_rate * random.uniform(0.8, 1.2)\n",
    "\n",
    "                tot_latency = trans_latency + comp_latency + ret_latency\n",
    "\n",
    "                tot_latencies.append(tot_latency)\n",
    "\n",
    "                Q_max = max([noise_factors[idx], quality_factors[idx], res_factors[idx]])\n",
    "                Q_min = min([noise_factors[idx], quality_factors[idx], res_factors[idx]])\n",
    "\n",
    "                cur_noise = (noise_factors[idx] - Q_min) / (Q_max - Q_min)\n",
    "                cur_quality = (quality_factors[idx] - Q_min) / (Q_max - Q_min)\n",
    "                cur_resolution = (res_factors[idx] - Q_min) / (Q_max - Q_min)\n",
    "\n",
    "                tot_qual = cur_noise + cur_quality + cur_resolution\n",
    "                tot_qualities.append(tot_qual)\n",
    "\n",
    "                T_req_i = gen_truncnorm(0, T_req_val, 0, 1, 1)[0]\n",
    "                Q_req_i = random.uniform(0.0, Q_req_val)\n",
    "\n",
    "                cur_val = 0\n",
    "\n",
    "                if (tot_qual >= Q_req_i) and (tot_latency <= T_req_i):\n",
    "                    cur_val = k[1] * (tot_qual - Q_req_i) + k[2] * (T_req_i - tot_latency) + k[3]\n",
    "                    case_1.append(cur_val)\n",
    "                elif (tot_qual >= Q_req_i) and (tot_latency > T_req_i):\n",
    "                    cur_val = k[4] * (tot_qual - Q_req_i) + k[5]\n",
    "                    case_2.append(cur_val)\n",
    "                elif (tot_qual < Q_req_i) and (tot_latency <= T_req_i):\n",
    "                    cur_val = k[6] * (T_req_i - tot_latency) + k[7]\n",
    "                    case_3.append(cur_val)\n",
    "                else:\n",
    "                    cur_val = 0\n",
    "                    case_4.append(cur_val)\n",
    "\n",
    "                val.append(cur_val)\n",
    "\n",
    "    print(np.array(val).shape)\n",
    "    val = np.array(val)\n",
    "    XX = val.reshape(x, y, z)\n",
    "\n",
    "    batch = torch.from_numpy(XX)\n",
    "    prices= VCG(batch, \"marginal\")\n",
    "    prices = prices.detach().numpy()\n",
    "    print(\"payoff\", float(prices.sum()) / n_auctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 7)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
